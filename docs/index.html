<!DOCTYPE html>
<html>
<head>
</head>
<body>
    <div style="border: 2px solid rgb(209, 206, 206); border-radius: 15px; padding: 10px;width:1100px; margin:auto;box-shadow: 1px 1px 2px 6px rgb(209, 206, 206)">
    <h1><p style="font-size:1.3em;text-align:center; font-family: 'Times New Roman'">SEFD : Learning to Distill Complex Pose and Occlusion</p></h1>
    <h2><p style="color:gray;font-size:0.9em;text-align:center; font-family: 'Times New Roman'">Anonymous ICCV submission</p></h2>
    <h2><p style="color:gray;font-size:0.7em;text-align:center; font-family: 'Times New Roman';font-weight: normal;">Paper ID : 11451</p></h2>
    <div style="border: 2px solid white; border-radius: 15px; padding: 10px;width:1100px; margin:auto"></div>
    <center>
    <img src="smpl_edge_visualization_output.png" alt="My Image" width="1000">
    <h3><p style="font-size:0.9em;text-align:center; font-family: 'Times New Roman';font-weight: normal;">
        Qualitative comparison of the baseline 3DCrowdNet and the proposed feature distillation 
        SMPL overlapping edge. <br/>
        <strong>(a)</strong> and <strong>(b)</strong> show complex poses and <strong>(c)</strong> and <strong>(d)</strong> shows occluded situations.
    </p></h3>
    </center>
    </div>
    </div>
    <br/>
    <div style="border: 2px solid rgb(209, 206, 206); border-radius: 15px; padding: 10px;width:1100px; margin:auto;box-shadow: 1px 1px 2px 6px rgb(209, 206, 206)">
    <h2><p style="font-size:1.3em;text-align:center; font-family: 'Times New Roman';font-weight: normal;">Feature distillation Learning</p></h1>
    <div style="border: 2px solid white; border-radius: 15px; width:1000px; margin:auto;height: 200;">
    <h3><p style="color:black;font-size:0.9em; font-family: 'Times New Roman';font-weight: normal;">Conventional distillation methods for human poses aim to lighten student models. Our feature distillation aims to distill the ground-truth feature representations of the teacher model to the student model solving the real-environment condition without ground-truth.
        also, this is designed to reduce the structural gap between simple edge map and SMPL overlap edge</p></h3>
    </div>
    </div>
    <br/>
    <div style="border: 2px solid rgb(209, 206, 206); border-radius: 15px; padding: 10px;width:1100px; margin:auto;box-shadow: 1px 1px 2px 6px rgb(209, 206, 206)">
    <h2><p style="font-size:1.3em;text-align:center; font-family: 'Times New Roman';font-weight: normal;">Abstract</p></h1>
    <div style="border: 2px solid white; border-radius: 15px; width:1000px; margin:auto;height: 200;">
    <h3><p style="color:black;font-size:0.9em; font-family: 'Times New Roman';font-weight: normal;">This paper addresses the problem of three-dimensional (3D) human mesh estimation in complex poses and occluded situations. 
        Although many improvements have been made in 3D human mesh estimation using the two-dimensional (2D) pose with occlusion between humans, occlusion from complex poses and other objects remains a consistent problem. 
        Therefore, we propose the novel <strong>Skinned Multi-Person Linear (SMPL) Edge Feature Distillation (SEFD)</strong> that demonstrates robustness to complex poses and occlusions, without increasing the number of parameters compared to the baseline model. 
        The model generates an SMPL overlapping edge similar to the ground truth that contains target person boundary and occlusion information, performing subsequent feature distillation in a simple edge map. 
        We also perform experiments on various benchmarks and exhibit fidelity both qualitatively and quantitatively. 
        Extensive experiments prove that our method outperforms the state-of-the-art method by 2.8% in MPJPE and 1.9% in MPVPE on a benchmark 3DPW dataset in the presence of domain gap. 
        <strong>Also, our method is superior in 3DPW-OCC, 3DPW-PC, RH-Dataset, OCHuman, CrowdPose, and LSP dataset in which occlusion, com plex pose, and domain gap exist.</strong></p></h3>
    </div>
    </div>
    <br/>
    <div style="border: 2px solid rgb(209, 206, 206); border-radius: 15px; padding: 10px;width:1100px; margin:auto;box-shadow: 1px 1px 2px 6px rgb(209, 206, 206)">
    <div style="border: 2px solid white; border-radius: 15px; width:1000px; margin:auto;height: 200;">
    <h2><p style="font-size:1.3em; font-family: 'Times New Roman';font-weight: normal;">SMPL Edge Feature Distillatino (SEFD)</p></h2>
    <h3><p style="color:black;font-size:0.9em; font-family: 'Times New Roman';font-weight: normal;">The figure below is the overall flow of our method.
        It consists of four components: Input Stage, SMPL Edge Generator, Teacher Model Training, and Student Model Training.
        To train the Teacher Model, an SMPL edge map must be generated through the SMPL Edge Generator in the Input Stage. After this process, the generated SMPL edge map is concatenated with the Input image and used to train the Teacher Model.
        After training the Teacher Model in this way, only the encoder of the Teacher Model is used to train the encoder of the Student Model through feature distillation. The input to the Student Model is obtained by passing it through a simple edge detector (e.g. Canny edge).</p></h3>
    <img src="main_model.png" alt="My Image" width="1000">
    <h3><p style="color:black;font-size:0.9em; font-family: 'Times New Roman';font-weight: normal;">To elaborate further, the SMPL Edge Generator consists of Projection, Edge Detection, Adaptive Dilation, and Overlap. For the Loss in Feature Distillation, 
        we used the Log Softmax Loss that we found, and we connected the 3rd and 4th feature maps for Feature Connection. 
        An explanation of Adaptive Dilation is provided below, and the reason for selecting the Feature Connection number and Log Softmax Loss and the results are mentioned below. <br/>
        <strong>We have added a GIF animation below just in case you have trouble understanding. Please check it out if you need further clarification.</strong></p></h3>
    <img src="main_model_gif.gif" alt="My Image" width="1000">
    </div>
    </div>
    </div>
    </div>
    <br/>
    <div style="border: 2px solid rgb(209, 206, 206); border-radius: 15px; padding: 10px;width:1100px; margin:auto;box-shadow: 1px 1px 2px 6px rgb(209, 206, 206)">
    <div style="border: 2px solid white; border-radius: 15px; width:1000px; margin:auto;height: 200;">
    <h2><p style="font-size:1.3em; font-family: 'Times New Roman';font-weight: normal;">Visualization Results</p></h2>
    <img src="SOTA.png" alt="My Image" width="1000">
    <h3><p style="color:black;font-size:0.9em; font-family: 'Times New Roman';font-weight: normal;">The above result image is a comparison of our method with other State-of-the-Art methods such as I2L-MeshNet, SPIN, and 3DCrowdNet. 
        Only the 3DCrowdNet, which considers occlusion, and our method produced plausible results. In the first row, although 3DCrowdNet plausibly detects the mesh, it fails to properly extract the person at the very back. 
        On the other hand, our method successfully extracts all three individuals plausibly. In the second row, when the person at the front performs a complex pose, 3DCrowdNet misses it, whereas our method detects it plausibly. 
        In the last row, due to the complex pose, 3DCrowdNet fails to resolve the issue of the hand being projected forward, but our method shows a visually appealing result with all hands positioned behind the individuals.
        <br/>
        <br/>
    <img src="complex_case.png" alt="My Image" width="1000">
    <img src="Occlusion_case.png" alt="My Image" width="1000">
    <img src="Occlusion+Complex_case.png" alt="My Image" width="1000">
    <h3><p style="color:black;font-size:0.9em; font-family: 'Times New Roman';font-weight: normal;">The above images show, from left to right, the input image, input 2D pose, 3DCrowdNet, and our method, respectively. 
        All of these images are from the CrowdPose test set and demonstrate how our method is more robust in complex poses and occlusion compared to 3DCrowdNet. 
        They demonstrate how well our method performs in challenging situations involving complex poses and occlusion.
        <br/>
        <br/>
    </div>
    </div>

</body>
</html>
